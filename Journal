27.dec.2017
-generate tsv file with labels given to the sentences from the test set to view where most issues occur

Main issues were regarding:
-the 0 at the end of sentences which is a character format issue that turns '.' into '0'.
-identifiying as 'DOS' numbers that indicate a time period e.g. 'two to three days'
-not identifying 'international units' as 'UNIT'
-not identifying as 'DOS' complex dosages e.g. '30-50mg' -> perhaps splitting numbers from letters would solve this issue
-line 7692
-not identifiying 'mg/l'

Questions:
-how do I treat adjectives that are attached to the UNIT? e.g. 'DAILY dose'?

Conclusion:
-Although there were many false positives and false negatives, a few inconsistencies were indeed detected in the dataset.
-average f1-score increased by 4 percent after this attempt. great!!

TO-DO:
-maybe experiment with different features?
-punctuation should not be classified as DOS or UNIT
-split sentences by '-', '/' and maybe '.' (I saw 2 sentences marked as one)
-create 'contains_dosage(sentence)' function to be able to increase dataset size.

11.jan.2018
Idea:
	there is a weight parameter that I could set in the labeling process. (maybe set weight for '.' to 0)

13.feb.2018
-what should the final application do?
-include comparisons on different algorithms?
-research paper?

answer "I don't know"
precision > recall
lod initiative + yago + dbpedia
notez orice citesc! sa am pt bibliografie, bookmarks etc.


17.feb.2018
-1/2 formatted incorrectly
-fixed '.' formatting problem
-'4-8' cataloged as JJ (adjective)
-anywhere there is a formatting problem, it is replaced by '??' and this causes bad classification => remake corpus


18.feb.2018
-remade corpus; performance improvement from the start.
-issues identifying interval ('1 to 3') dosages
-is 'daily dose' a UNIT?
-started labeling both 'TREZIX' and 'tablet' as UNIT
-something causes labels to be placed one step lower than they should:
    0.9-2.4	JJ	DOS
    grams	NNS	UNIT
    daily	RB	O
    in	IN	O
    3	CD	DOS
    or	CC	O
    4	CD	DOS
    equally	RB	UNIT
    divided	VBN	UNIT
    doses	NNS	UNIT
    (	(	O
    i.e.	JJ	O
    ,	,	O
    300-600	JJ	DOS !!! O
    mg	NN	UNIT !!! DOS
    3	CD	O !!! UNIT
    or	CC	O
    4	CD	O
    times	NNS	O
    daily	RB	O
    )	)	O
    .	.	O


21.feb.2018
-split "0.15-mg/kg" or "8-mg" by hyphen?
-deleted sentences that were missclassified because of formatiing issues (the one above and one more)

22.feb.2018
-generated "corpus2" with all sentences that may contain "DOS" or "UNIT"
-definitely need to separate by "-" and "/". first I have to remake the main corpus

26.feb.2018
-remade initial dataset splitting by "-" and "/"
-add as feature words in front of a preceding parenthesis for the current word.
-added word2 feature.

1.mar.2018
-10-fold cross validation results (done four times and appended); crfUtil.plot_error_distrib() plots the error from these:
    unit_precision
    [0.988, 0.945, 0.987, 0.943, 0.988, 1.0, 0.966, 0.985, 0.964, 0.987, 0.96, 0.955, 0.962, 1.0, 0.976, 0.944, 0.987, 0.989, 0.985, 0.974, 0.974, 0.949, 0.987, 0.987, 1.0, 0.973, 0.976, 0.975, 0.987, 0.988, 0.955, 0.978, 0.988, 0.957, 0.985, 0.973, 0.957, 0.985, 0.989, 1.0]

    dos_precision
    [0.978, 0.945, 0.989, 0.953, 0.989, 1.0, 0.979, 0.987, 0.95, 0.975, 1.0, 0.971, 0.959, 1.0, 0.966, 0.961, 0.989, 0.989, 0.988, 0.956, 0.978, 0.968, 0.979, 0.957, 1.0, 0.966, 1.0, 0.976, 0.989, 0.978, 0.96, 0.971, 0.97, 0.975, 0.975, 0.965, 1.0, 0.987, 0.981, 1.0]

    unit_recall
    [0.941, 0.986, 0.974, 0.856, 0.964, 1.0, 0.933, 0.971, 0.953, 0.937, 0.911, 0.944, 0.949, 0.963, 0.965, 0.971, 0.974, 0.939, 0.971, 0.974, 0.949, 0.892, 0.951, 0.987, 0.932, 0.973, 0.943, 0.907, 0.975, 0.976, 0.988, 0.978, 0.964, 0.957, 0.957, 0.887, 0.905, 0.985, 0.959, 0.965]

    dos_recall
    [0.968, 0.966, 0.946, 0.935, 0.957, 0.988, 0.96, 0.987, 0.979, 0.952, 0.956, 0.953, 0.989, 0.939, 0.977, 0.936, 0.958, 0.969, 0.963, 0.978, 0.968, 0.968, 0.979, 0.947, 0.897, 0.988, 0.948, 0.965, 0.946, 0.989, 0.969, 0.971, 0.96, 1.0, 0.952, 0.954, 0.951, 0.963, 0.954, 0.979]

    unit_f1
    [0.964, 0.965, 0.98, 0.897, 0.976, 1.0, 0.949, 0.978, 0.959, 0.961, 0.935, 0.949, 0.955, 0.981, 0.971, 0.958, 0.98, 0.964, 0.978, 0.974, 0.961, 0.919, 0.969, 0.987, 0.965, 0.973, 0.96, 0.94, 0.981, 0.982, 0.971, 0.978, 0.976, 0.957, 0.971, 0.928, 0.931, 0.985, 0.974, 0.982]

    dos_f1
    [0.968, 0.966, 0.946, 0.935, 0.957, 0.988, 0.96, 0.987, 0.979, 0.952, 0.956, 0.953, 0.989, 0.939, 0.977, 0.936, 0.958, 0.969, 0.963, 0.978, 0.968, 0.968, 0.979, 0.947, 0.897, 0.988, 0.948, 0.965, 0.946, 0.989, 0.969, 0.971, 0.96, 1.0, 0.952, 0.954, 0.951, 0.963, 0.954, 0.979]

    total_precision
    [0.983, 0.945, 0.988, 0.948, 0.988, 1.0, 0.973, 0.986, 0.957, 0.981, 0.981, 0.964, 0.96, 1.0, 0.971, 0.953, 0.988, 0.989, 0.986, 0.964, 0.976, 0.959, 0.983, 0.971, 1.0, 0.969, 0.989, 0.976, 0.988, 0.983, 0.957, 0.974, 0.978, 0.967, 0.98, 0.969, 0.98, 0.986, 0.985, 1.0]

    total_recall
    [0.955, 0.975, 0.959, 0.898, 0.96, 0.993, 0.947, 0.979, 0.967, 0.944, 0.935, 0.949, 0.971, 0.949, 0.971, 0.953, 0.965, 0.954, 0.967, 0.976, 0.959, 0.933, 0.966, 0.965, 0.913, 0.981, 0.946, 0.936, 0.959, 0.983, 0.978, 0.974, 0.962, 0.98, 0.954, 0.922, 0.929, 0.973, 0.956, 0.972]

    total_f1
    [0.969, 0.96, 0.973, 0.922, 0.974, 0.997, 0.96, 0.983, 0.962, 0.962, 0.958, 0.956, 0.965, 0.974, 0.971, 0.953, 0.977, 0.971, 0.977, 0.97, 0.968, 0.945, 0.974, 0.968, 0.954, 0.975, 0.967, 0.955, 0.973, 0.983, 0.968, 0.974, 0.97, 0.973, 0.967, 0.944, 0.954, 0.98, 0.97, 0.986]

4.Mar.2018
-generated corpus2 from model trained with "corp.tsv"
-fixed slashes-dashes issue
-did not verify the formatting issue found on 18.feb
-trained model for 1h on "corpus2.tsv", obtained the following results:
            precision	recall	f1-measure
        UNIT 	0.967		0.978	0.967
        DOS 	0.971		0.973	0.972
        avg 	0.969		0.971	0.970

5.Mar.2018
-created validation corpus from initial dataset
-created issues file from corpus2 and corrected many mis-classifications
-remaining sentences plus others from corpus2 constitute the new corpus for training
-there might be some duplicates because of the way corpus2 was generated
-found sentence with formatting issue (what causes this?) - seems that all of them contain 'e.g.' or 'i.e.'
-changed every 'e.g.' instance with 'e.g' and 'i.e.' with 'i.e' and that fixed the issue
-multiple punctuation signs in the same word might cause the issue
-10-fold cross validation results:
    [0.994, 0.97, 0.994, 0.994, 1.0, 0.988, 0.975, 0.95, 0.976, 1.0]
    [0.98, 0.973, 0.966, 0.985, 0.995, 0.995, 0.972, 0.975, 0.969, 1.0]
    [0.961, 0.97, 0.969, 0.978, 0.983, 0.959, 0.963, 0.935, 0.988, 1.0]
    [0.957, 0.973, 0.977, 0.99, 0.984, 0.954, 0.972, 0.965, 0.964, 0.964]
    [0.978, 0.97, 0.981, 0.986, 0.991, 0.973, 0.969, 0.942, 0.982, 1.0]
    [0.957, 0.973, 0.977, 0.99, 0.984, 0.954, 0.972, 0.965, 0.964, 0.964]
    [0.987, 0.972, 0.979, 0.989, 0.997, 0.991, 0.973, 0.963, 0.972, 1.0]
    [0.959, 0.972, 0.973, 0.984, 0.984, 0.956, 0.968, 0.951, 0.975, 0.98]
    [0.973, 0.972, 0.976, 0.987, 0.99, 0.974, 0.971, 0.957, 0.974, 0.99]

7.Mar.2018
-started labeling for "WHO"
    The	DT	O
    daily	JJ	O
    nutrient	NN	O
    requirements	NNS	O
    of	IN	O
    an	DT	O
    average	JJ	WHO
    adult	NN	WHO
    patient	NN	WHO
    ,	,	WHO
    not	RB	WHO
    hypermetabolic	JJ	WHO
    ,	,	WHO
    in	IN	WHO
    an	DT	WHO
    acceptable	JJ	WHO
    weight	NN	WHO
    range	NN	WHO
    and	CC	WHO
    with	IN	WHO
    restricted	JJ	WHO
    physical	JJ	WHO
    activity	NN	WHO

24.Mar.2018
-created a function that generates a tree with nodes containing the named entities

25.Mar.2018
-created a function that calculates the distance between two trees without taking into consideration the names of the
nodes, just the structure